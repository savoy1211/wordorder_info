# Word Order Entropy of Multiple Langauges
 
This project uses n-gram models to calculate the word order entropy of languages such as English, Dutch, Turkish, Mandarin, and Polish. For each language, we've created a corpus containing texts from Project Gutenberg.

### 0. Corpora

Request for a link to the corpora at wrnkle at gmail dot com
Then create a new folder ```texts```:
```sh
$ mkdir texts
$ cd texts
```
Move the corpora into this directory

### 1. Setup

Create a virtual environment called ```wordorder-info-env```:
```sh
$ python3 -m venv wordorder-info-env
```
Activate ```wordorder-info-env```:
```sh
$ source wordorder-info-env/bin/activate
```
Install project dependencies:	
```sh
$ pip install -r requirements.txt
```

### 2. Get Results

Get the entropy of words and set of words of English (this will create a text file of your results):
```sh
$ python main_train_english.py
```
The script does the following:
 - Preprocesses the texts of the training and test sets with the ```ModulateText``` object
 - Creates an n-gram model using the training set with the ```NgramModel``` object
 - Returns a text file indicating the entropy of words and set of words of the test set using probabilities generated by the training 

### 3. Analyze Results

In a Jupyter Notebook, open ``` plot_3grams_ENGLISH.ipynb```  to analyze your results.

### 4. Repeat for Other Languages

### *Note: 
#### On the ```NgramModel``` object

By default, the n-gram model is set as a trigram model. Each language's n-gram model's alpha should be a little different in order to optimize the language model, i.e. to minimize perplexity.

So far, here are the most optimal alphas we've found for some languages:
* i) English: ```alpha=0.01```
* ii) Dutch: ```alpha=0.001```
* iii) Hungarian: ```alpha=0.0001```
* iv) Turkish: ```alpha=1```
* v) Mandarin: ```alpha=0.5```
* vi) Greek: ```alpha=0.01```

#### On the ```ModulateText``` object
The ```ModulateText``` object takes in a parameter called ```state``` which is equal to either ```ordered outbound```, ```ordered inbound```, ```random outbound```, or ```random inbound``` 

```outbound``` indicates that the sliding window goes past sentence bounds while ```inbound``` means that the sliding window stays within sentence bounds.

```ordered``` indicates that the words of the corpus are in order, and ```random``` tells the ```ModulateText``` object to randomize the words of the corpus. 

```random inbound``` randomizes words within sentence bounds and ```random outbound``` randomizes words past sentence bounds.

i.e. Given a corpus: "Jack hit the ball. Pat caught the ball."
- ```random inbound``` may return: ["hit", "ball", "the", "jack", "ball", "caught", "path", "the"]
- ```random outbound``` may return: ["caught", "the", "the", "pat", "ball", "ball", "jack"]

